#  DPT笔记

参考资料：

***

### 概述

DPT，全称为 Dense Prediction Transformer，是由 René Ranftl 等人在2021年提出的一个深度学习模型。它的核心贡献在于**首次成功地将纯粹的 Vision Transformer (ViT) 架构用作骨干网络，并高效地解决了密集预测（Dense Prediction）任务**。
- **密集预测任务是什么？** 这类任务要求模型对输入图像的**每一个像素**都生成一个或多个预测值。典型的例子包括：
	- **单目深度估计 (Monocular Depth Estimation):** 预测每个像素离相机的距离。
	- **语义分割 (Semantic Segmentation):** 为每个像素分配一个类别标签（如“人”、“车”、“天空”）。
- **DPT的意义何在？** 在DPT出现之前，密集预测任务的主流模型大多基于全卷积网络（FCNs），例如U-Net。这些模型通过卷积操作来提取局部特征，虽然有效，但其感受野（receptive field）相对有限，难以捕捉图像的全局上下文信息。而Vision Transformer (ViT) 通过其自注意力机制（Self-Attention）能够有效捕捉全局信息，但在设计上是为图像分类任务服务的，输出的是一个单一的类别标签，无法直接用于像素级的密集预测。DPT巧妙地将ViT强大的全局特征提取能力与卷积网络的空间重建能力结合起来，解决了这一难题。

### DPT 模型架构详解

DPT模型可以清晰地分为两个主要部分：一个**基于ViT的编码器 (Encoder)** 和一个**卷积解码器 (Decoder)**。

### DPT模型结构示意图

#### 1. 编码器 (Encoder)：Vision Transformer (ViT)

DPT直接采用了标准的Vision Transformer作为其编码器部分，用于从输入图像中提取特征。这个过程可以分解为以下几步：
**a. 图像分块与嵌入 (Image Patching and Embedding)**
首先，模型会将输入的2D图像 $x \in \mathbb{R}^{H \times W \times C}$ (H是高, W是宽, C是通道数) 分割成一系列固定大小的小图像块（patches）。例如，一张 $224 \times 224$ 的图像可以被分割成 $14 \times 14$ 个 $16 \times 16$ 大小的图像块。
然后，每个图像块被展平（flatten）成一个一维向量，并通过一个线性投射层（Linear Projection）将其映射到一个固定维度的嵌入向量（embedding）。这个过程可以用下面的公式简单表示：
$$
z_0 = [x_{class}; E(p_1); E(p_2); \dots; E(p_N)] + E_{pos}
$$
让我们来解释这个公式：

- $p_i$ 是第 $i$ 个展平后的图像块向量。
- $E$ 是线性投射层，它本质上是一个可学习的权重矩阵。
- $E(p_i)$ 就是每个图像块经过投射后得到的“token”或嵌入向量。
- $N$ 是图像块的总数 (例如 $14 \times 14 = 196$)。
- $x_{class}$ 是一个特殊的可学习的 [CLS] token。在原始的ViT中，这个token最终的输出状态被用来进行图像分类。DPT保留了这个token，但其主要作用是参与全局信息的交互。
- $E_{pos}$ 是位置嵌入（Positional Embedding）。因为Transformer的自注意力机制本身不包含位置信息，所以必须显式地为每个token添加一个位置编码，告诉模型每个图像块的原始空间位置。
  经过这一步，一张完整的2D图像就被转换成了一个1D的token序列。

**b. Transformer编码层 (Transformer Encoder Layers)**
这个token序列接着被送入一堆标准的Transformer编码层。每个编码层主要由两个子模块构成：

- **多头自注意力模块 (Multi-Head Self-Attention, MHSA):** 这是Transformer的核心。它允许模型中的每一个token（代表一个图像块）关注到序列中的所有其他token，并计算它们之间的相关性权重。这使得模型能够捕捉到图像中任意两个位置之间的长距离依赖关系，从而获得真正的**全局上下文信息**。
  其核心计算公式为：

$$
\text{Attention}(Q, K, V) = \text{softmax}\left(\frac{QK^T}{\sqrt{d_k}}\right)V
$$
- $Q$ (Query), $K$ (Key), $V$ (Value) 是从输入token序列通过线性变换得到的三個矩阵。
- 公式的核心思想是：用每个token的 $Q$ 去和所有token的 $K$ 计算相似度（通过点积 $QK^T$），然后通过softmax归一化得到注意力权重，最后将这个权重加权应用到所有token的 $V$ 上。这本质上是一个动态的、基于内容寻址的加权求和过程。
- “多头”则意味着这个过程会并行地进行多次，每一“头”学习不同的注意力模式，从而捕捉更丰富的特征关系。

**前馈网络 (Feed-Forward Network, FFN):** 这是一个简单的多层感知机（MLP），通常由两个线性层和一个激活函数（如GELU）组成，用于对自注意力模块的输出进行非线性变换和特征增强。

这些编码层会堆叠多次（例如，ViT-Base有12层，ViT-Large有24层），每一层都会对token序列进行更深层次的特征提炼。

-----
#### 2. 解码器 (Decoder)：卷积与上采样

编码器的输出是一个经过充分信息交互和提炼的token序列。然而，对于密集预测任务，我们需要的是一个与原图分辨率相同（或接近）的像素级预测图。解码器的作用就是将这个一维的token序列**重新组装**并**上采样**回一个2D的特征图。
DPT的解码器设计是其成功的关键，它巧妙地融合了来自Transformer不同层级的特征。
**a. 重组操作 (Reassemble Operation)**
解码器的第一步是将编码器输出的token序列（除 [CLS] token外）重新排列组合成一个2D的特征图。

- 假设ViT编码器处理了 $N=H_p \times W_p$ 个图像块token，每个token的维度是 $D$。
- 重组操作就是将这 $N$ 个维度为 $D$ 的token，按照它们原先在图像中的空间位置，重新排列成一个 $H_p \times W_p \times D$ 的三维特征图。例如，对于 $224 \times 224$ 的输入和 $16 \times 16$ 的patch大小，我们会得到一个 $14 \times 14 \times D$ 的特征图。

**b. 逐层上采样与融合 (Progressive Upsampling and Fusion)**
DPT的解码器包含多个上采样阶段，逐步将低分辨率的特征图恢复到原始尺寸。其精妙之处在于，它不仅仅使用了Transformer最后一层的输出，而是**融合了来自编码器多个中间层的特征**。
具体来说，一个典型的上采样阶段包含以下步骤：

1. **特征图处理:** 对从上一阶段传入的特征图（或初始的重组特征图）应用一个卷积层进行处理。
2. **特征融合 (Fusion):** 将处理后的特征图与**来自ViT编码器相应层级的token重组后的特征图**在通道维度上进行拼接（Concatenate）。例如，解码器的第一阶段会融合来自ViT较深层（如第9、12层）的特征，而后续阶段会融合来自较浅层（如第3、6层）的特征。
3. **上采样:** 使用双线性插值（Bilinear Interpolation）或转置卷积（Transposed Convolution）将融合后的特征图尺寸放大2倍。
4. **卷积处理:** 再通过一个卷积层对上采样后的特征进行进一步的提炼。
   这个“融合-上采样”的过程会重复进行，直到特征图的分辨率恢复到输入图像的一半。最后，再通过一个最终的卷积层生成最终的像素级预测。

**为什么需要融合多层特征？**

- **深层特征:** 来自ViT编码器后几层的特征，经过了多次自注意力计算，包含了丰富的**全局语义信息**（知道图像里“有什么”）。
- **浅层特征:** 来自编码器前几层的特征，更多地保留了**局部细节和空间信息**（知道物体的边缘、纹理“在哪里”）。
通过将不同层级的特征融合在一起，DPT的解码器能够同时利用全局的语义理解和局部的空间细节，这对于生成高质量、边缘清晰的密集预测结果至关重要。
### DPT模型的优势总结
1. **强大的全局上下文建模能力:** 凭借Transformer的自注意力机制，DPT能够捕捉图像中任意像素之间的长距离依赖关系，这对于理解大的场景和物体间的关系非常有帮助，远超传统CNN有限的感受野。
2. **灵活的骨干网络:** DPT证明了ViT作为一种通用的特征提取器，可以被成功应用于密集预测任务，打破了CNN在该领域的垄断地位。
3. **高效的多尺度特征融合:** 其精心设计的解码器能够有效地融合ViT编码器不同阶段的特征，兼顾了高级语义信息和低级空间细节，从而实现了卓越的性能。
总而言之，DPT模型的核心思想是“**用Transformer的全局视野进行编码，用卷积的局部精细操作进行解码**”，通过一个巧妙的解码器将这两者的优势结合起来，为密集预测领域开辟了一个新的、高效的范式。
