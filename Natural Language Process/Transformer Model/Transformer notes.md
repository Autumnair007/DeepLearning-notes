#  Transformer笔记（DeepSeek生成）

学习资料：[Transformer通俗笔记：从Word2Vec、Seq2Seq逐步理解到GPT、BERT-CSDN博客](https://blog.csdn.net/v_JULY_v/article/details/127411638?ops_request_misc=%7B%22request%5Fid%22%3A%229d7c8f6c3ec83074f33e1e1ebe062d64%22%2C%22scm%22%3A%2220140713.130102334.pc%5Fall.%22%7D&request_id=9d7c8f6c3ec83074f33e1e1ebe062d64&biz_id=0&utm_medium=distribute.pc_search_result.none-task-blog-2~all~first_rank_ecpm_v1~hot_rank-1-127411638-null-null.142^v102^pc_search_result_base3&utm_term=seq2seq模型&spm=1018.2226.3001.4187)



------

