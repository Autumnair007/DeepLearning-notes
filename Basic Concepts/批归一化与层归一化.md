#  批归一化与层归一化笔记（DeepSeek生成）

学习资料：[深度解析Batch normalization（批归一化） - 知乎](https://zhuanlan.zhihu.com/p/435507061)

[【深度学习】批归一化（Batch Normalization）_batch normalization 对离散特征归一化吗-CSDN博客](https://blog.csdn.net/vict_wang/article/details/88075861?ops_request_misc=%7B%22request%5Fid%22%3A%22f4b11ccd4f984dd8e4346a104481a429%22%2C%22scm%22%3A%2220140713.130102334..%22%7D&request_id=f4b11ccd4f984dd8e4346a104481a429&biz_id=0&utm_medium=distribute.pc_search_result.none-task-blog-2~all~top_positive~default-1-88075861-null-null.142^v102^pc_search_result_base3&utm_term=批归一化&spm=1018.2226.3001.4187)

------

# Batch Normalization（批归一化）

Batch Normalization（批归一化）是一种用于深度神经网络中的技术，旨在加速训练、提高模型稳定性并增强泛化能力。以下是对其详细解释：

---

## **1. 核心思想**
批归一化通过**标准化**神经网络每一层的输入，缓解**内部协变量偏移（Internal Covariate Shift）**问题。内部协变量偏移指训练过程中，由于前层参数更新导致后续层输入分布不断变化，迫使网络不断适应新的分布，从而降低训练效率。批归一化通过强制每层输入的均值和方差稳定，使训练更高效。

---

## **2. 具体操作步骤**
### **训练阶段**
1. **计算小批量的均值和方差**：
   对于一个大小为 $m$ 的小批量数据 $B = \{x_1, x_2, ..., x_m\}$，对每个特征维度（或通道）计算：
   $$
   \mu_B = \frac{1}{m} \sum_{i=1}^m x_i \quad \text{(均值)}
   $$
   $$
   \sigma_B^2 = \frac{1}{m} \sum_{i=1}^m (x_i - \mu_B)^2 \quad \text{(方差)}
   $$

2. **归一化**：
   对每个样本 $x_i$ 进行标准化：
   $$
   \hat{x}_i = \frac{x_i - \mu_B}{\sqrt{\sigma_B^2 + \epsilon}} \quad (\epsilon \text{为防除零的小常数})
   $$

3. **缩放与平移**：
   引入可学习参数 $\gamma$（缩放因子）和 $\beta$（平移因子），恢复网络的表达能力：
   $$
   y_i = \gamma \hat{x}_i + \beta
   $$
   $\gamma$ 和 $\beta$ 通过反向传播优化，允许网络决定是否保留归一化效果。

### **测试阶段**
- 使用训练时计算的**指数移动平均（EMA）**的全局均值 $\mu_{\text{global}}$ 和方差 $\sigma_{\text{global}}^2$ 进行归一化，确保结果确定性。

---

## **3. 不同网络结构中的应用**
- **全连接层**：对每个特征维度独立归一化。
- **卷积层**：对每个通道单独归一化。假设输入为四维张量 $(N, C, H, W)$，对每个通道 $C$ 计算 $N \times H \times W$ 个元素的均值和方差。

---

## **4. 优势**
- **加速训练**：稳定的输入分布允许使用更大学习率。
- **降低对初始化的敏感度**：网络对权重初始化要求更宽松。
- **正则化效果**：小批量的统计量引入噪声，轻微抑制过拟合。
- **缓解梯度消失/爆炸**：归一化使激活值分布在敏感区域（如ReLU的线性区）之外。

---

## **5. 实现细节**
- **位置**：通常置于线性层（如全连接、卷积）之后，激活函数之前。
- **Batch Size影响**：过小的Batch Size（如1）会导致统计量不准确，建议使用较大Batch Size。
- **参数数量**：每个通道/特征对应一对可学习的 $\gamma$ 和 $\beta$，参数量为 $2C$（$C$ 为通道数）。

---

## **6. 数学原理**
- **反向传播**：需计算均值、方差的梯度。现代框架（如PyTorch、TensorFlow）可自动处理。
- **移动平均更新**：训练时更新全局统计量：
  $$
  \mu_{\text{global}} = \text{momentum} \cdot \mu_{\text{global}} + (1 - \text{momentum}) \cdot \mu_B
  $$
  $$
  \sigma_{\text{global}}^2 = \text{momentum} \cdot \sigma_{\text{global}}^2 + (1 - \text{momentum}) \cdot \sigma_B^2
  $$
  其中 $\text{momentum}$ 通常接近1（如0.9）。

---

## **7. 局限与替代方案**
- **小Batch Size问题**：可改用Layer Normalization（RNN常用）或Instance Normalization（风格迁移常用）。
- **依赖Batch统计量**：某些场景（如在线学习）需谨慎使用。

---

## **8. 代码示例（PyTorch）**
------

以下是一个**实际运行过程的逐步解析**，结合代码示例说明批归一化层（BatchNorm）在训练和测试阶段的具体变化。我们以PyTorch中的`BatchNorm1d`为例，模拟一个简单的全连接网络前向传播过程。

---

### **(1) 代码示例回顾**
```python
import torch
import torch.nn as nn

# 定义网络结构（输入784维，隐藏层256维，输出10维）
model = nn.Sequential(
    nn.Linear(784, 256),   # 全连接层
    nn.BatchNorm1d(256),   # 批归一化层
    nn.ReLU(),             # 激活函数
    nn.Linear(256, 10)
)

# 模拟输入数据（batch_size=4，输入维度784）
x = torch.randn(4, 784)    # 4个样本，每个样本784维
```

---

### **(2)前向传播的逐步变化**
假设输入数据为 `x`（形状 `[4, 784]`），我们逐步跟踪数据经过每一层的变化：

#### **步骤1：全连接层（Linear）**
- 输入 `x` 经过 `nn.Linear(784, 256)`，输出形状变为 `[4, 256]`。
- 假设输出值为（仅示例，非真实计算）：
  ```python
  linear_output = torch.tensor([
      [1.2, -0.5, 0.3, ...],  # 样本1的256维输出
      [0.8, 1.5, -0.7, ...],   # 样本2
      [-1.0, 0.2, 1.1, ...],   # 样本3
      [0.5, -1.2, 0.9, ...]    # 样本4
  ])
  ```

#### **步骤2：批归一化层（BatchNorm1d）**
- **输入**：`linear_output`（形状 `[4, 256]`），对**每个特征维度**（共256维）独立进行归一化。
- **以第一个特征维度（第0列）为例**：
  
  - 该列数据为 `[1.2, 0.8, -1.0, 0.5]`（4个样本的第0维特征值）。
  - **计算均值和方差**：
    
    ```python
    mean = (1.2 + 0.8 - 1.0 + 0.5) / 4 = 0.375
    var = ((1.2-0.375)^2 + (0.8-0.375)^2 + (-1.0-0.375)^2 + (0.5-0.375)^2) / 4 ≈ 0.747
    ```
  - **归一化**（假设 `epsilon=1e-5`）：
    ```python
    normalized = (x - mean) / sqrt(var + epsilon)
    # 例如第一个样本的第0维：
    normalized_1 = (1.2 - 0.375) / sqrt(0.747 + 1e-5) ≈ 0.954
    ```
  - **缩放和平移**（使用可学习的 $\gamma$ 和 $\beta$，初始值通常为 $\gamma=1$, $\beta=0$）：
    ```python
    output = gamma * normalized + beta
    # 若 gamma=1, beta=0，则 output ≈ normalized_1 ≈ 0.954
    ```
- **对所有256维重复上述过程**，最终输出形状仍为 `[4, 256]`。

#### **步骤3：ReLU激活**
- 对批归一化后的输出应用 `ReLU`，保留正值，负值置零。
  ```python
  relu_output = torch.maximum(bn_output, 0)
  ```

#### **步骤4：下一个全连接层**
- 重复类似过程，直至输出最终结果。

---

### **(3)训练与测试阶段的差异**
#### **训练阶段**
- **动态统计量**：每次前向传播使用当前小批量的均值和方差（如步骤2所示）。
- **更新全局统计量**：通过移动平均累计全局均值和方差：
  
  ```python
  running_mean = momentum * running_mean + (1 - momentum) * batch_mean
  running_var = momentum * running_var + (1 - momentum) * batch_var
  ```

#### **测试阶段**
- **固定统计量**：使用训练时累计的 `running_mean` 和 `running_var` 归一化，而非当前批次统计量。
  ```python
  normalized = (x - running_mean) / sqrt(running_var + epsilon)
  ```

---

### **(4) 参数更新过程**
- **可学习参数**：$\gamma$ 和 $\beta$ 通过梯度下降优化。
- **梯度计算**：PyTorch的 `autograd` 会自动计算归一化操作的梯度，无需手动实现。

---

### **(5)可视化示例**
假设某一层的输入分布变化：
1. **未使用BatchNorm**：输入分布随训练剧烈波动，导致训练不稳定。
   ```
   Epoch 1: 分布范围 [-10, 10]
   Epoch 2: 分布范围 [-5, 15]
   ...
   ```
2. **使用BatchNorm**：输入分布被强制稳定在 $\mathcal{N}(0,1)$ 附近（若 $\gamma=1, \beta=0$）。
   ```
   Epoch 1: 分布范围 ~[-2, 2]
   Epoch 2: 分布范围 ~[-2, 2]
   ...
   ```

---

### **(6)关键点总结**
1. **归一化维度**：对每个特征维度独立计算。
2. **训练/测试差异**：测试时使用全局统计量，避免依赖batch。
3. **参数作用**：$\gamma$ 和 $\beta$ 恢复网络表达能力，避免归一化破坏原有特征分布。

通过这种机制，批归一化层显著提升了网络的训练效率和稳定性。

------

## 9. **总结**

批归一化通过标准化层输入，显著提升训练速度和模型鲁棒性，是深度学习中的基础技术之一。理解其原理与实现细节，有助于更有效地设计网络结构及调参。

------

# 层归一化 (Layer Normalization, LN)

**核心目标:**

层归一化的主要目的是对神经网络某一层（通常是全连接层或 Transformer 中的子层）的输入进行规范化处理，以帮助稳定训练过程，加速模型收敛，并可能提高模型的泛化能力。

**基本思想:**

与批归一化（Batch Normalization）不同，层归一化不是在批次（batch）维度上计算统计量，而是在**单个样本**的**特征（feature）维度**上进行计算。也就是说，对于层的一个输入样本（一个向量），它会计算这个样本所有特征的均值和方差，然后用这些统计量来归一化该样本的每一个特征。

**数学公式与步骤:**

假设一个层接收到的输入是一个向量 $x$，这个向量代表**一个**数据样本在该层的输入表示，它有 $H$ 个特征（或维度）。即 $x = (x_1, x_2, ..., x_H)$。

层归一化的计算过程如下：

1.  **计算均值 (Mean) $\mu$:**
    计算该输入向量 $x$ 中所有元素的均值。
    $$
    \mu = \frac{1}{H} \sum_{i=1}^{H} x_i
    $$
    这里的求和 $\Sigma$ 是对向量 $x$ 的所有 $H$ 个元素进行的。

2.  **计算方差 (Variance) $\sigma^2$:**
    计算该输入向量 $x$ 中所有元素的方差。
    $$
    \sigma^2 = \frac{1}{H} \sum_{i=1}^{H} (x_i - \mu)^2
    $$
    同样，这里的求和也是对向量 $x$ 的所有 $H$ 个元素进行的。

3.  **归一化 (Normalize):**
    对向量 $x$ 中的每一个元素 $x_i$ 进行归一化，使其具有零均值和单位方差（近似）。
    $$
    \hat{x}_i = \frac{x_i - \mu}{\sqrt{\sigma^2 + \epsilon}}
    $$
    *   $\hat{x}_i$ 是归一化后的第 $i$ 个元素。
    *   $\epsilon$ (epsilon) 是一个非常小的正数（例如 1e-5），用于防止分母为零，增加数值稳定性。

4.  **缩放和平移 (Scale and Shift):**
    为了让网络能够学习恢复可能在归一化过程中丢失的信息，引入了两个可学习的参数：缩放因子 $\gamma$ (gamma) 和平移因子 $\beta$ (beta)。这两个参数通常也是向量，维度与 $x$ 相同（即 $H$ 维）。
    $$
    y_i = \gamma_i \hat{x}_i + \beta_i
    $$
    *   $y_i$ 是层归一化最终输出的第 $i$ 个元素。
    *   $\gamma$ 和 $\beta$ 是模型的参数，会在训练过程中通过反向传播学习得到。它们允许网络自适应地调整归一化后特征的尺度和均值。如果网络发现原始的激活值尺度更优，它可以学习让 $\gamma$ 接近原始标准差，让 $\beta$ 接近原始均值，从而在一定程度上“撤销”归一化。

**总结:**

层归一化通过计算**单个样本内所有特征**的均值和方差，对该样本的特征进行归一化，然后通过可学习的缩放和平移参数 $\gamma$ 和 $\beta$ 调整输出。这个过程完全在单个样本内部完成，不依赖于批次中的其他样本，因此对批次大小不敏感，特别适用于处理序列数据（如 RNN 和 Transformer）的场景。

------

**选择指南总结:**

- **当你使用卷积神经网络 (CNN) 处理图像等数据，并且可以负担得起较大的批次大小时 (例如 > 16 或 32)，优先考虑使用批归一化 (BN)。** 这是 CNN 中的标准实践，效果通常很好。
- **当你处理序列数据，使用循环神经网络 (RNN, LSTM, GRU) 或 Transformer 时，优先考虑使用层归一化 (LN)。** 这是这些架构中的标准选择。
- **当你的批次大小非常小（由于内存限制或其他原因）时，即使在 CNN 中，也可以考虑使用层归一化 (LN) 或其他替代方案（如 Group Normalization）。**
- **当你希望训练和推理行为完全一致，简化部署时，层归一化 (LN) 是更简单的选择。**
